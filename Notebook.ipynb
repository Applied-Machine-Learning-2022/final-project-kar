{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Artist classification by painting"
      ],
      "metadata": {
        "id": "RWoBuUnRNVSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project explores the merits of using machine learning in \n",
        "supplementing art expertsâ€™ efforts in identifying forgeries among disputed paintings. From the movement of brushstrokes to the use of light and dark, successful algorithms will likely incorporate many aspects of a painter's unique style. "
      ],
      "metadata": {
        "id": "z1zA887sPuMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Multi Label Image Classification Simplified Model](https://www.analyticsvidhya.com/blog/2019/04/build-first-multi-label-image-classification-model-python/)"
      ],
      "metadata": {
        "id": "hsF9DTpE-knO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanatory Data Analysis"
      ],
      "metadata": {
        "id": "EeXN_UbfPxoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ],
      "metadata": {
        "id": "-8VtLdKFP65v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by using the \"train.zip\" data [Painter by Numbers](https://www.kaggle.com/competitions/painter-by-numbers/overview) from Kaggle.As you can see the train.zip is 38.7 GB. That is a lot and will take a lot of time to download/load. \n",
        "\n",
        "For our timeline, instead of using the full dataset we will use a sub portion of the full train data: \"train_1.zip\". "
      ],
      "metadata": {
        "id": "FGqDPLCHm6FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all libraries\n",
        "import PIL as Image\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XdpFaSoYn9Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the first painting"
      ],
      "metadata": {
        "id": "2E4PSxynoFXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.open(r'C:\\Users\\14794\\Documents\\NACME_capstone\\train_1\\train_1\\1.jpg')"
      ],
      "metadata": {
        "id": "pFEogmyHn5dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look of the first 10 images in the train_1 folder"
      ],
      "metadata": {
        "id": "nhdNUr45ouZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the train_1 folder\n",
        "\n",
        "list_dir = os.listdir('train_1/train_1/')\n",
        "\n",
        "for i in len(list_dir):\n",
        "  if i < 10:\n",
        "    i.open(r'C:/Users/14794/Documents/NACME_capstone/train_1/train_1/' + i)\n",
        "  else:\n",
        "    break\n"
      ],
      "metadata": {
        "id": "2GeSyv2S6wXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take notice how the images are ordered and sorted. We can see that the images don't go completely in order from 1.2.3.. and so on. Instead it goes 1.10.11.12.14... and so on. Next load in all_data_info.csv."
      ],
      "metadata": {
        "id": "DhRYLIGD7wm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "labels = pd.read_csv('C:/Users/14794/Documents/NACME_capstone/all_data_info.csv/all_data_info.csv')\n",
        "labels.head(10)"
      ],
      "metadata": {
        "id": "HCEs9Qrq6-fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing the first 10 samples, we can see that this dataframe contains all the image in all the train and test dataset. We will need to sort through the dataframe and use only rows corresponding to our train_1 dataset. "
      ],
      "metadata": {
        "id": "xhNz_EgR8nEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_df = pd.DataFrame(list_dir, columns = ['new_filename'])\n",
        "for i in list_df['new_filename']:\n",
        "    list_df['path'] = path + i\n",
        "print(list_df)"
      ],
      "metadata": {
        "id": "q_x9j4fl68O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We labeled the list_dir column name \"new_filename\", since our code will need a column in common to merge efficiently. We also decided to append the path into the dataframe for future purposes if needed. "
      ],
      "metadata": {
        "id": "LqYboebs9UCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.merge(labels, list_df, on =\"new_filename\")\n",
        "new_df = new_df.dropna()"
      ],
      "metadata": {
        "id": "Jt9fG6UFPvzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By dropping all our naN values, our data lost roughly 2000 rows of data."
      ],
      "metadata": {
        "id": "A5q101YiUjNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we can add additional images to the train dataset, by using train_2 or other train files.**"
      ],
      "metadata": {
        "id": "VedMIKTn-UK7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REw-EsTCNLr_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}