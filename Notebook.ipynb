{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Artist classification by painting"
      ],
      "metadata": {
        "id": "RWoBuUnRNVSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project explores the merits of using machine learning in \n",
        "supplementing art expertsâ€™ efforts in identifying forgeries among disputed paintings. From the movement of brushstrokes to the use of light and dark, successful algorithms will likely incorporate many aspects of a painter's unique style. "
      ],
      "metadata": {
        "id": "z1zA887sPuMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Multi Label Image Classification Simplified Model](https://www.analyticsvidhya.com/blog/2019/04/build-first-multi-label-image-classification-model-python/)"
      ],
      "metadata": {
        "id": "hsF9DTpE-knO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanatory Data Analysis"
      ],
      "metadata": {
        "id": "EeXN_UbfPxoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ],
      "metadata": {
        "id": "-8VtLdKFP65v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by using the \"train.zip\" data [Painter by Numbers](https://www.kaggle.com/competitions/painter-by-numbers/overview) from Kaggle.As you can see the train.zip is 38.7 GB. That is a lot and will take a lot of time to download/load. \n",
        "\n",
        "For our timeline, instead of using the full dataset we will use a sub portion of the full train data: \"train_1.zip\". "
      ],
      "metadata": {
        "id": "FGqDPLCHm6FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.python.keras.preprocessing.image\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "XdpFaSoYn9Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the first painting"
      ],
      "metadata": {
        "id": "2E4PSxynoFXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.open(r'C:\\Users\\14794\\Documents\\NACME_capstone\\train_1\\train_1\\1.jpg')"
      ],
      "metadata": {
        "id": "pFEogmyHn5dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look of the first 10 images in the train_1 folder"
      ],
      "metadata": {
        "id": "nhdNUr45ouZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the train_1 folder\n",
        "\n",
        "list_dir = os.listdir('train_1/train_1/')\n",
        "\n",
        "for i in len(list_dir):\n",
        "  if i < 10:\n",
        "    i.open(r'C:/Users/14794/Documents/NACME_capstone/train_1/train_1/' + i)\n",
        "  else:\n",
        "    break\n"
      ],
      "metadata": {
        "id": "2GeSyv2S6wXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take notice how the images are ordered and sorted. We can see that the images don't go completely in order from 1.2.3.. and so on. Instead it goes 1.10.11.12.14... and so on. Next load in all_data_info.csv."
      ],
      "metadata": {
        "id": "DhRYLIGD7wm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "labels = pd.read_csv('C:/Users/14794/Documents/NACME_capstone/all_data_info.csv/all_data_info.csv')\n",
        "labels.head(10)"
      ],
      "metadata": {
        "id": "HCEs9Qrq6-fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing the first 10 samples, we can see that this dataframe contains all the image in all the train and test dataset. We will need to sort through the dataframe and use only rows corresponding to our train_1 dataset. "
      ],
      "metadata": {
        "id": "xhNz_EgR8nEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_df = pd.DataFrame(list_dir, columns = ['new_filename'])\n",
        "for i in list_df['new_filename']:\n",
        "    list_df['path'] = path + i\n",
        "print(list_df)"
      ],
      "metadata": {
        "id": "q_x9j4fl68O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We labeled the list_dir column name \"new_filename\", since our code will need a column in common to merge efficiently. We also decided to append the path into the dataframe for future purposes if needed. "
      ],
      "metadata": {
        "id": "LqYboebs9UCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.merge(labels, list_df, on =\"new_filename\")\n",
        "new_df = new_df.dropna()"
      ],
      "metadata": {
        "id": "Jt9fG6UFPvzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By dropping all our naN values, our data lost roughly 2000 rows of data."
      ],
      "metadata": {
        "id": "A5q101YiUjNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can do some exploratory data analysis (EDA)."
      ],
      "metadata": {
        "id": "YKwgH-OdNTyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_df[\"artist\"].unique())        #unique names of artists\n",
        "print(new_df[\"artist\"].nunique())       #count of unique artists\n",
        "print(new_df.columns)                   #see all the column names\n",
        "count = new_df.groupby(['artist'])['artist'].count()  #count the amount of times each artist has an entry\n",
        "print(count.sort_values(ascending = False).tail(10))  #sort the names of artists and show the 10 least promenant artists\n",
        "print(count.sort_values(ascending = False).head(10))  #sort the names of artists and show the 10 most promenant artists"
      ],
      "metadata": {
        "id": "KlVKsxUsNSwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we know that we have around 500 artist, with around 8,000 photos to use. We also see how many of the artists from this reduced dataset have very little paintings. Many of the artist only have 1 entry, and others have less than 5 which makes it very difficult for our model to use them to train."
      ],
      "metadata": {
        "id": "qodlKGwmQP4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix this, we will have to fix our data!\n",
        " - Here we will merge the dataframe holding the picures and the dataframe holding all the information"
      ],
      "metadata": {
        "id": "Y5EQasRlQqhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.merge(labels, list_df, on =\"new_filename\") \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "pmrDVGIZQtFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We merged the dataframe so that the dataframe we have will only include the names of the files in the training folder, this way we don't tell the computer to show us a picture we don't have."
      ],
      "metadata": {
        "id": "Kf05Li0PRZed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is changing all the image files to text so the computer can actually read them."
      ],
      "metadata": {
        "id": "h28MqJLKYDDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "painting_images = []\n",
        "    for i in tqdm(range(list_df.shape[0])):\n",
        "        img = image.load_img('train_1/train_1/'+ new_df['new_filename'][i], target_size=(224, 224, 3))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255\n",
        "        painting_images.append(img)\n",
        "    X = np.array(painting_images)\n",
        "    y = np.array(new_df['artist'])"
      ],
      "metadata": {
        "id": "qZPlGRm6X3Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a method which will create the model. We created our own model going off of popular models we found online."
      ],
      "metadata": {
        "id": "uFK2iBONYLad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(224, 224, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # new addition\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "DaAQVvciYx62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our second model we created, it's not as good as the first model."
      ],
      "metadata": {
        "id": "e2WQrvkNZEdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RESNET50(num_classes):\n",
        "    resnet = Sequential()\n",
        "    pretrained = tensorflow.keras.applications.ResNet50(include_top = False,\n",
        "                                                        input_shape = (224, 224, 3),\n",
        "                                                        pooling = 'avg',\n",
        "                                                        classes = 5,\n",
        "                                                        weights = 'imagenet')\n",
        "    for layer in pretrained.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    resnet.add(pretrained)\n",
        "    resnet.add(Flatten())\n",
        "    resnet.add(Dense(128, activation='relu'))\n",
        "    resnet.add(Dropout(0.5))\n",
        "    resnet.add(Dense(64, activation='relu'))\n",
        "\n",
        "    resnet.add(Dense(32, activation='relu'))\n",
        "    resnet.add(Dropout(0.5))\n",
        "\n",
        "    resnet.add(Dropout(0.25))\n",
        "    resnet.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "3vIdHfpkZDjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create the function that will clean our data further! Getting rid of the artist with little amounts of pictures, we also train_test_split here."
      ],
      "metadata": {
        "id": "W9spf1m_Y2Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_data(x_array, y_array):\n",
        "    dataframe_1 = pd.DataFrame(x_array.reshape((y_array.shape[0], -1)), columns=list(range(150528)))\n",
        "    dataframe_2 = pd.DataFrame(y_array, columns=[\"filename\"])\n",
        "    df = pd.merge(dataframe_1, dataframe_2, left_index=True, right_index=True)\n",
        "    df = df.dropna()\n",
        "    df['count'] = df.groupby('filename')['filename'].transform('count')\n",
        "    dataframe = df[df['count'] >= 10]\n",
        "    print(dataframe.head(10))\n",
        "    labels = [x for x in dataframe[\"filename\"].unique()]\n",
        "    num_artists = len(labels)\n",
        "    print(num_artists)\n",
        "\n",
        "    print(dataframe.isna().sum())\n",
        "\n",
        "    X_array = dataframe[list(range(150528))].to_numpy()\n",
        "    Y_array = dataframe['filename'].to_numpy()\n",
        "    artists = list(np.unique(Y_array))\n",
        "    num_classes = len(artists)\n",
        "    Y_array = np.array([artists.index(i) for i in Y_array])\n",
        "    Y_array = to_categorical(Y_array)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X_array, Y_array, random_state=42, test_size=0.15, shuffle=True)\n",
        "    x_train = x_train.reshape((y_train.shape[0], 224, 224, 3))\n",
        "    x_test = x_test.reshape((y_test.shape[0], 224, 224, 3))\n",
        "    print(x_train, y_test, y_train, y_test)\n",
        "    print(x_train.shape, y_train.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test, num_artists"
      ],
      "metadata": {
        "id": "aglDV1L-Y-lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the main code"
      ],
      "metadata": {
        "id": "VedMIKTn-UK7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REw-EsTCNLr_"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    x_array, y_array = data_preprocessing()\n",
        "    x_train, x_test, y_train, y_test, num_classes = cleaning_data(x_array, y_array)\n",
        "    model = create_model(num_classes)\n",
        "    model.summary()\n",
        "    model.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size = 18)\n",
        "    model.save('./ckpts/Model_1')\n",
        "    ResNet = RESNET50(num_classes)\n",
        "    ResNet.summary()\n",
        "    ResNet.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "    ResHistory = ResNet.fit(x_train, y_train, epochs = 10, batch_size = 18)\n",
        "    ResNet.save('.ckpts/ResNet')\n",
        "\n",
        "\n",
        "    ResNet.evaluate(x_test, y_test)"
      ]
    }
  ]
}